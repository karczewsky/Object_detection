{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Praca Inżynierska\n",
    "## Jakub Karczewski"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-98508e620b5e378a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-98508e620b5e378a\");\n          const url = new URL(\"/\", window.location);\n          const port = 9000;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tensor_board --host localhost --port 9000\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from functools import reduce\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from utilities.metrics import mean_average_precision\n",
    "from utilities.inference import infer_image\n",
    "\n",
    "DIR_INPUT = 'data/classic'\n",
    "DIR_OUTPUT = 'data/inference'\n",
    "DF_CLASSIC_TRAIN = pd.read_csv('csv_dataframes/input_classic.csv')\n",
    "DEVICE_VALIDATION = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Przygotowanie danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class PharmacyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        unique_labels = dataframe['label'].unique()\n",
    "        unique_labels_dataframe = pd.DataFrame(data={\n",
    "            'label': unique_labels,\n",
    "            'label_id': [i+1 for i in range(unique_labels.shape[0])]\n",
    "        })\n",
    "\n",
    "        dataframe = dataframe.merge(unique_labels_dataframe, on='label')\n",
    "\n",
    "        self.image_names = dataframe['image'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.unique_labels_dataframe = unique_labels_dataframe\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_name = self.image_names[index]\n",
    "        records = self.df[self.df['image'] == image_name]\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_name}', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        boxes = []\n",
    "        for row in records.iterrows():\n",
    "            row = row[1]\n",
    "            boxes.append([row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': torch.as_tensor(records['label_id'].values, dtype=torch.int64),\n",
    "            'image_id': torch.as_tensor([index], dtype=torch.int64),\n",
    "            'area': torch.as_tensor(area, dtype=torch.float32),\n",
    "            'iscrowd': torch.zeros((records.shape[0],), dtype=torch.uint8)\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': target['labels']\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        return image, target, image_name\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_names.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Przygotowanie modelu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.4),\n",
    "        A.ShiftScaleRotate(p=0.3),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "def get_validation_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "class FasterRcnn(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            train_dataset: torch.utils.data.dataset.Subset,\n",
    "            valid_dataset:torch.utils.data.dataset.Subset,\n",
    "            num_classes: int,\n",
    "            batch_size: int,\n",
    "            optimizer = torch.optim.AdamW,\n",
    "            optimizer_keys = None,\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            scheduler_keys = None,\n",
    "            # lr is only used when found, otherwise optimizer_keys lr is used\n",
    "            lr = None\n",
    "    ):\n",
    "        super(FasterRcnn, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = valid_dataset\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_keys = optimizer_keys\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_keys = scheduler_keys\n",
    "        self.lr = lr\n",
    "\n",
    "        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "            pretrained=True,\n",
    "            pretrained_backbone=True,\n",
    "            trainable_backbone_layers=5\n",
    "        )\n",
    "\n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "       train_loader = DataLoader(self.train_dataset,\n",
    "                                 batch_size=self.batch_size,\n",
    "                                 num_workers=6,\n",
    "                                 shuffle=True,\n",
    "                                 collate_fn=collate_fn)\n",
    "       return train_loader\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        valid_loader = DataLoader(self.valid_dataset,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  num_workers=6,\n",
    "                                  shuffle=False,\n",
    "                                  collate_fn=collate_fn)\n",
    "        return valid_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = [p for p in self.model.parameters() if p.requires_grad]\n",
    "\n",
    "        if self.lr is not None:\n",
    "            self.optimizer_keys['lr'] = self.lr\n",
    "\n",
    "        optimizer = self.optimizer(params=params, **self.optimizer_keys)\n",
    "        return ({\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': self.scheduler(optimizer=optimizer, **self.scheduler_keys),\n",
    "            'interval': 'epoch',\n",
    "            'monitor': 'val_mAP'\n",
    "        })\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets, img_name = batch\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "        # separate losses\n",
    "        loss_dict = self.model(images, targets)\n",
    "        # total loss\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # loss_dict contains training metrics:\n",
    "        # - loss_objectness: błąd informujący o rozróżnianiu obiektu od tła\n",
    "        # - loss_rpn_box_reg: błąd pozycjonowania proposal box'u przez RPN w wyniku regresji\n",
    "        # - loss_box_reg: błąd pozycjonowania anochor box'u w proposal box'ach\n",
    "        # - loss_classifier: błąd zaklasyfikowania obiektu do danej klasy\n",
    "        self.log_dict(loss_dict, prog_bar=True, logger=True)\n",
    "        self.log('main_loss', losses, prog_bar=False, logger=True)\n",
    "\n",
    "        return {'loss': losses}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets, img_name = batch\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        outputs = self.model(images, targets)\n",
    "\n",
    "        l_targets = []\n",
    "        l_preds = []\n",
    "\n",
    "        for pred, target in zip(outputs, targets):\n",
    "            # sometimes target['labels'] is longer than target['boxes']\n",
    "            target['labels'] = target['labels'][:len(target['boxes'])]\n",
    "\n",
    "            t_targets = torch.cat([\n",
    "                torch.full((len(target['boxes']), 1), target['image_id'].item()).to(DEVICE_VALIDATION),\n",
    "                torch.unsqueeze(target['labels'], 0).t().to(DEVICE_VALIDATION),\n",
    "                target['boxes'].to(DEVICE_VALIDATION)\n",
    "            ], dim=1)\n",
    "            l_targets.append(t_targets)\n",
    "\n",
    "\n",
    "            t_pred = torch.cat([\n",
    "                torch.full((len(pred['boxes']), 1), target['image_id'].item()).to(DEVICE_VALIDATION),\n",
    "                torch.unsqueeze(pred['labels'], 0).t().to(DEVICE_VALIDATION),\n",
    "                torch.unsqueeze(pred['scores'], 0).t().to(DEVICE_VALIDATION),\n",
    "                pred['boxes'].to(DEVICE_VALIDATION)\n",
    "            ], dim=1)\n",
    "            l_preds.append(t_pred)\n",
    "\n",
    "        t_target = reduce(lambda a, b: torch.cat([a, b], dim=0), l_targets)\n",
    "        t_pred = reduce(lambda a, b: torch.cat([a, b], dim=0), l_preds)\n",
    "\n",
    "        return {\n",
    "            'target': t_target,\n",
    "            'pred': t_pred\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        t_target = reduce(lambda a, b: torch.cat([a, b], dim=0), [x['target'] for x in val_step_outputs])\n",
    "        t_pred = reduce(lambda a, b: torch.cat([a, b], dim=0), [x['pred'] for x in val_step_outputs])\n",
    "\n",
    "        val_mean_average_precision = mean_average_precision(\n",
    "            t_pred, t_target, iou_threshold=0.5, ap_calculation='COCO'\n",
    "        )\n",
    "        self.log('val_mAP', val_mean_average_precision.item(), prog_bar=True, logger=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. (Opcjonalnie) Trening modelu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = PharmacyDataset(DF_CLASSIC_TRAIN, DIR_INPUT, transforms=get_train_transform())\n",
    "num_classes = len(DF_CLASSIC_TRAIN['label'].unique()) + 1\n",
    "\n",
    "train_cases = int(len(dataset) * 0.80)\n",
    "val_cases = len(dataset) - train_cases\n",
    "train_dataset, valid_dataset = random_split(dataset, lengths=[train_cases, val_cases], generator=torch.Generator().manual_seed(42))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkarczewski/miniconda3/envs/torchvision/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory saved_models/ exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | FasterRCNN | 41.5 M\n",
      "-------------------------------------\n",
      "41.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "41.5 M    Total params\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92744164830c440d95b0175027ed5a98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c22b6bac7024317a1fc9bd5b41eab41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "719eb78d4a7241c2846fe68b3cc75a01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41d658f0789c4a47b1e999cf985a3635"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b33f6ff63ec4826b9092dc6a87b0e5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c10d5121f6384b21982a0a7412b10b5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b7c845ed05c40a4b0f1a13252192725"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9a7fbfc012f4479b6da94f69c303c7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4993740471924a49b4e2702af646f8ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "561408f341124c1c9f949b559291b6c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "953e1ba2ae84461bb1d0cd5d8c2926b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "386d6e8c86d94bdc9d8de33e3e9d6446"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cb6505b5f6f48faa57270c81bc9e825"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fea811baa51243e3a3e73a3aa49017a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7417d13a607493eb79eea67879a57b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca5246131e564c05be5ba5b47110c66c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11f76db4d5164214b6da7440ff7efe38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb3e220aa21e4001b7356a2a3d8a0f4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fe48a11a09443db802ba2ef007746be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4b76921e6b44db295e0959254778e87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbd2d4c6a78242c6a43665cfdc380a71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41649d5865c942e5b37683e6b6acdbfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "169f026b24e84e60bab4419415cdc9f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "205a11ad58eb43ffbd9da773efc97bd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0abb86931e146109996a15dcafc4154"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e53f423ac39f4411a7b9ef504ed3fdf4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8146631dd32459a8d4c69159e8d0ab5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd99702c0147495e886bb759a4238a43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bbd8a483b75472aad37f717697fbf2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "616549fbb3184f819047492bbe572c15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "944e969905174bcb9b19db0edf129129"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "454844ebca1544e897dcb39c5e86eab6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0626b369057b42e1bce29913338851f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a787ed89b4547399967429b2ad43571"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "892f8e4150434278bfde25101f9ce175"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "012f731011da42b4a66dd54715111785"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4887dcfb935444ed9d961bde6e6d56d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65618bc196b34d4cb1883b0ad6c948fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41e752afc354405bbb54da506a21db06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb30ddc0c2824c76a073685b194d8460"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ec50878ec704bb781bf22007716c03d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05c5d2e8197b43aa9b9d3438b327c8ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3f98fce3f644ae5868e3837265c8fa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f3d5b4c007140c291d7225f7c013650"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f99045246454accbb67cd2454629766"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "362c3622a2f04922a9cae7af60293976"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'optimizer': torch.optim.AdamW,\n",
    "        'optimizer_keys': {'lr': 0.0004, 'weight_decay': 1e-2},\n",
    "        'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'scheduler_keys': {'factor': 0.1, 'mode': 'max', 'patience': 10}\n",
    "    }\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    run_category_name = config['optimizer'].__name__\n",
    "    run_version_name = '-'.join([f'{k}={v}' for k, v in config['optimizer_keys'].items()])\n",
    "\n",
    "    model = FasterRcnn(\n",
    "        train_dataset=train_dataset,\n",
    "        valid_dataset=valid_dataset,\n",
    "        num_classes=num_classes,\n",
    "        batch_size=1,\n",
    "        optimizer=config['optimizer'],\n",
    "        optimizer_keys=config['optimizer_keys'],\n",
    "        scheduler=config['scheduler'],\n",
    "        scheduler_keys=config['scheduler_keys']\n",
    "    )\n",
    "\n",
    "    tb_logger = pl.loggers.TensorBoardLogger(\n",
    "        save_dir=\"./tensor_board\",\n",
    "        name=run_category_name,\n",
    "        version=run_version_name\n",
    "    )\n",
    "\n",
    "    early_stopping = pl.callbacks.EarlyStopping(\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        monitor='val_mAP',\n",
    "        min_delta=0.0,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    model_checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath='saved_models/',\n",
    "        filename=f'{run_category_name}+{run_version_name}',\n",
    "        mode='max',\n",
    "        monitor='val_mAP',\n",
    "        save_top_k=1\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        logger=tb_logger,\n",
    "        accumulate_grad_batches=1,\n",
    "        accelerator='dp',\n",
    "        gradient_clip_val=0.5,\n",
    "        max_epochs=150,\n",
    "        auto_lr_find=True,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "    # trainer.tune(model)\n",
    "    trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. (Opcjonalnie) Załadowanie wytrenowanego modelu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF_TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-53b827b54a08>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mload_pretrained\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;31m# model with .ckpt extension\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFasterRcnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_from_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'example_model.ckpt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDF_TRAIN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.007\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfreeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'DF_TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "load_pretrained = True\n",
    "\n",
    "if load_pretrained:\n",
    "    # model with .ckpt extension\n",
    "    model = FasterRcnn.load_from_checkpoint('example_model.ckpt', df=DF_TRAIN, learning_rate=0.007, batch_size=1)\n",
    "model.freeze()\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "\n",
    "print('Model ready for inference')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Test modelu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = PharmacyDataset(DF_TRAIN, DIR_INPUT, transforms=get_validation_transform())\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=6,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for (images, targets, image_names) in iter(data_loader):\n",
    "    images = list(image.to('cuda') for image in images)\n",
    "    targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "\n",
    "    for (image, target, image_name) in zip(images, targets, image_names):\n",
    "        # image -> tensor of shape(3, 1200, 1600)\n",
    "        # target -> dict with fields: boxes(tensor of shape(N, 4)), image_id(tensor of shape(1)),...\n",
    "        boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
    "        sample = image.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "        infer_image(\n",
    "            model=model,\n",
    "            image=image,\n",
    "            show_image=False,\n",
    "            labels_dict=dataset.unique_labels_dataframe,\n",
    "            score_threshold=0.5,\n",
    "            save_dir=DIR_OUTPUT,\n",
    "            save_name=image_name\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Próba wyuczenia modelu na bazie 'faceów' produktów"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PharmacyDatasetFaces(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        unique_labels = dataframe['label'].unique()\n",
    "        unique_labels_dataframe = pd.DataFrame(data={\n",
    "            'label': unique_labels,\n",
    "            'label_id': [i+1 for i in range(unique_labels.shape[0])]\n",
    "        })\n",
    "\n",
    "        dataframe = dataframe.merge(unique_labels_dataframe, on='label')\n",
    "\n",
    "        self.image_names = dataframe['image'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.unique_labels_dataframe = unique_labels_dataframe\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_name = self.image_names[index]\n",
    "        records = self.df[self.df['image'] == image_name]\n",
    "\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_name}', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        boxes = []\n",
    "        for row in records.iterrows():\n",
    "            row = row[1]\n",
    "            boxes.append([row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': torch.as_tensor(records['label_id'].values, dtype=torch.int64),\n",
    "            'image_id': torch.as_tensor([index], dtype=torch.int64),\n",
    "            'area': torch.as_tensor(area, dtype=torch.float32),\n",
    "            'iscrowd': torch.zeros((records.shape[0],), dtype=torch.uint8)\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': target['labels']\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        return image, target, image_name\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_names.shape[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "BackboneWithFPN(\n  (body): IntermediateLayerGetter(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): FrozenBatchNorm2d(64)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(64)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(64)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(256)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): FrozenBatchNorm2d(256)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(64)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(64)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(256)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(64)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(64)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(256)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(128)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(128)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(512)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): FrozenBatchNorm2d(512)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(128)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(128)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(512)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(128)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(128)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(512)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(128)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(128)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(512)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(256)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(256)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(1024)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): FrozenBatchNorm2d(1024)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(256)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(256)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(1024)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(256)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(256)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(1024)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(256)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(256)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(1024)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(256)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(256)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(1024)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(256)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(256)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(1024)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(512)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(512)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(2048)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): FrozenBatchNorm2d(2048)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(512)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(512)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(2048)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): FrozenBatchNorm2d(512)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): FrozenBatchNorm2d(512)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): FrozenBatchNorm2d(2048)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (fpn): FeaturePyramidNetwork(\n    (inner_blocks): ModuleList(\n      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (layer_blocks): ModuleList(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (extra_blocks): LastLevelMaxPool()\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.backbone"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}